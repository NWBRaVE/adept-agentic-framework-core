{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03: Scientific Workflow and RAG\n",
    "\n",
    "This notebook focuses on the `ScientificWorkflowAgent`'s Retrieval-Augmented Generation (RAG) capabilities. You will learn how to upload various document types (CSV, PDF, DOCX, images, TXT, TEX), process them to create embeddings, and then query their content using natural language.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Before running this notebook, ensure that the Docker services for Chapter 06 are up and running. You can start them by navigating to the `chapter-06-advanced-multi-agent-orchestration` directory and executing the lifecycle script:\n",
    "\n",
    "```bash\n",
    "./start-chapter-resources.sh\n",
    "```\n",
    "\n",
    "Also, ensure you have an SSH session with port forwarding for OpenWebUI (`8902`), the Agent Gateway (`8083`), and the main MCP server (`8080`):\n",
    "\n",
    "```bash\n",
    "ssh -L 8902:localhost:8902 -L 8083:localhost:8083 -L 8080:localhost:8080 user@remote-server\n",
    "```\n",
    "\n",
    "## 1. Uploading and Processing Documents\n",
    "\n",
    "The RAG workflow begins by placing a document into the shared `data/uploaded_files` volume. Once the file is in place, we call the `process_uploaded_file` tool on the main MCP server to generate embeddings and index the document for RAG.\n",
    "\n",
    "For this example, we'll create a dummy CSV file and manually place it into the shared volume. In a real application, files would be uploaded via a dedicated UI or API that places them into this shared volume.\n",
    "\n",
    "First, let's define the content of our dummy CSV file and the path where it should be placed within the shared volume. You will need to manually create this file in your local `data/uploaded_files` directory (e.g., `docs/tutorial-branches/chapter-06-advanced-multi-agent-orchestration/data/uploaded_files/dummy_data.csv`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import uuid\n",
    "import io\n",
    "\n",
    "# Configuration\n",
    "DEFAULT_MCP_SERVER_URL = \"http://localhost:8080/mcp\" # Main MCP server for processing tools\n",
    "AGENT_GATEWAY_URL = \"http://localhost:8083/v1\" # Agent Gateway for chat interactions\n",
    "MODEL_ID = \"agentic-framework/scientific-agent-v1\"\n",
    "API_KEY = \"not-a-real-key\" # Dummy API key if auth is disabled\n",
    "\n",
    "# Create a dummy CSV file content\n",
    "csv_content = \"\"\"name,age,city\nAlice,30,New York\nBob,24,London\nCharlie,35,Paris\"\"\"\n",
    "dummy_filename = \"dummy_data.csv\"\n",
    "\n",
    "# Define the full path where the file should be manually placed\n",
    "file_path_on_server = f\"/app/data/uploaded_files/{dummy_filename}\"\n",
    "\n",
    "print(f\"Please manually create a file named '{dummy_filename}' in your local 'data/uploaded_files/' directory (e.g., docs/tutorial-branches/chapter-06-advanced-multi-agent-orchestration/data/uploaded_files/).\")\n",
    "print(f\"Paste the following content into it:\n---\n{csv_content}\n---\")\n",
    "print(f\"Once created, the file will be accessible by the MCP server at: {file_path_on_server}\")\n",
    "\n",
    "# Step 2: Call the process_uploaded_file tool on the main MCP server\n",
    "print(f\"\nProcessing manually placed file with MCP tool 'process_uploaded_file'...\")\n",
    "process_params = {\n",
    "    \"file_path_on_server\": file_path_on_server,\n",
    "    \"original_filename\": dummy_filename,\n",
    "    \"mcp_session_id\": str(uuid.uuid4()) # Use a new session ID for this example\n",
    "}\n",
    "\n",
    "mcp_call_payload = {\n",
    "    \"jsonrpc\": \"2.0\",\n",
    "    \"method\": \"tools/call\",\n",
    "    \"params\": {\n",
    "        \"name\": \"process_uploaded_file\",\n",
    "        \"arguments\": process_params\n",
    "    },\n",
    "    \"id\": str(uuid.uuid4())\n",
    "}\n",
    "\n",
    "try:\n",
    "    process_response = requests.post(DEFAULT_MCP_SERVER_URL, json=mcp_call_payload)\n",
    "    process_response.raise_for_status()\n",
    "    process_result = process_response.json()\n",
    "    print(\"Processing successful:\")\n",
    "    print(json.dumps(process_result, indent=2))\n",
    "    \n",
    "    # Extract the file_id for later use\n",
    "    file_id = process_result[\"result\"][\"result\"][\"file_id\"]\n",
    "    print(f\"\nExtracted file_id: {file_id}\")\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error during file processing: {e}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error decoding JSON response: {process_response.text if 'process_response' in locals() else ''}\")\n",
    "except KeyError as e:\n",
    "    print(f\"Missing key in JSON response: {e}. Full response: {process_result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Querying Processed Documents (RAG)\n",
    "\n",
    "Once a document is processed and indexed, you can use the `QueryProcessedDocumentData` tool (exposed by the `ScientificWorkflowAgent`) to ask questions about its content. The agent will use its RAG capabilities to retrieve relevant information and formulate an answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Ensure file_id is set from the previous cell's output\n",
    "if 'file_id' not in locals():\n",
    "    print(\"Please run the previous cell to upload and process a document first.\")\n",
    "else:\n",
    "    user_query = f\"What is Alice's age from the document with file_id {file_id}?\"\n",
    "    \n",
    "    client = openai.OpenAI(\n",
    "        base_url=AGENT_GATEWAY_URL,\n",
    "        api_key=API_KEY,\n",
    "    )\n",
    "    \n",
    "    print(f\"Sending query to agent: {user_query}\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_ID,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "                {\"role\": \"user\", \"content\": user_query}\n",
    "            ],\n",
    "            stream=False,\n",
    "        )\n",
    "        \n",
    "        print(\"\n--- Agent Response ---\")\n",
    "        if response.choices:\n",
    "            print(response.choices[0].message.content)\n",
    "        else:\n",
    "            print(\"The agent did not return any choices.\")\n",
    "            \n",
    "    except openai.APIConnectionError as e:\n",
    "        print(f\"Failed to connect to the Agent Gateway: {e}\")\n",
    "    except openai.APIStatusError as e:\n",
    "        print(f\"The Agent Gateway returned an error status code: {e.status_code}. Response: {e.response.text}\")\n",
    "    \"except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Listing Uploaded Files\n",
    "\n",
    "You can list all files that have been uploaded and processed in the current session using the `ListUploadedFiles` tool. This is useful for keeping track of the documents available for RAG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Call the list_uploaded_files tool on the main MCP server\n",
    "print(f\"Listing uploaded files for the current session...\")\n",
    "list_params = {\n",
    "    \"mcp_session_id\": file_id # Use the same session ID as the processed file\n",
    "}\n",
    "\n",
    "mcp_call_payload = {\n",
    "    \"jsonrpc\": \"2.0\",\n",
    "    \"method\": \"tools/call\",\n",
    "    \"params\": {\n",
    "        \"name\": \"list_uploaded_files\",\n",
    "        \"arguments\": list_params\n",
    "    },\n",
    "    \"id\": str(uuid.uuid4())\n",
    "}\n",
    "\n",
    "try:\n",
    "    list_response = requests.post(DEFAULT_MCP_SERVER_URL, json=mcp_call_payload)\n",
    "    list_response.raise_for_status()\n",
    "    list_result = list_response.json()\n",
    "    print(\"Uploaded files:\")\n",
    "    print(json.dumps(list_result, indent=2))\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error listing files: {e}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error decoding JSON response: {list_response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrated how to upload, process, and query documents using the `ScientificWorkflowAgent`'s RAG capabilities. In the next notebook, we will explore the `sandbox_mcp_server` for secure code execution.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}